## notes from intern Kaspersky

Creating transparency in AI decision-making

- Can AI be used in high risk situation? Will it think better than human (because AI cannot be shocked and etc) or worse (because AI do not have such life experience as humans)? 

- Google’s image recognition system wrongly classified images of minorities, the Apple Card which is administered by Goldman Sachs has come under recent scrutiny for gender bias, and software used to sentence criminals was found to be biased against minorities.

- Kathleen Walch is Managing Partner & Principal Analyst at AI Focused Research and Advisory firm Cognilytica (http://cognilytica.com), a leading analyst firm focused on application and use of artificial intelligence (AI) in both the public and private sectors. She is also co-host of the popular AI Today podcast, a top AI related podcast that highlights various AI use cases for both the public and private sector as well as interviews guest experts on AI related topics. - Partnership? We can make a project or even an episode of the podcast together.


AI as a form of Moral Advisor

- AI systems tend to be used as ‘recommender systems’ in online shopping, online entertainment (for example, music and movie streaming), and other realms. Some ethicists have discussed the advantages and disadvantages of AI systems whose recommendations could help us to make better choices and ones more consistent with our basic values. Perhaps AI systems could even, at some point, help us improve our values. - the usage of AI at court??


AI and the future of relationship

- AI-driven dating apps, as they might reinforce negative stereotypes and negative gender expectations

----

## notes from Coordinature:

       
        
   questions: 
   - The topic "train your ai as if you are a parent teaching a child":
   		- Does this the ai (chatbot or virtual character) is representing a child-like character? no
        - Does this mean that we are modeling the relationship between a mentor-like situation and a student? no
        - Does this mean that as the trainer of the ai, you can teach the ai any task you want it to be good at?no
        - Does this mean that the ai is focussed on asking child-like why questions to any information you give it, in order to understand the context? maybe
        
        - Is the goal of this excersise to focus on training an ai? no
     	- or is the goal of this excersise to recreate a special bond / connection with the ai? no
        
        internal questions:
        - When the user is a parents to the ai. "groom your ai."
        - what are tricky ethical issues that ml developers face?
        - what are controversial situations in relationship to "I trust the ai i am training"?

ai in companion situations and the influence on peoples psychology.
- how much can it be hacked to influence peoples psychology? 
- When programming these bots, how do we make sure that it can deal with this situation?
- usefullness of programming sensitivity.

Where there are tricky controversial scenario's like:
- people with mental health issues
- people with highly secretive jobs.
- people with dire living situations. (just lost your job, lost a loveone, financial issues, divorse etc.)
- people that just experienced trauma / victems of a crime.
- physical health limitations

or possible problems occur like:
- programming bias
- stimulating negative behaviour or thought patterns with the user

intent:
- the road paved with good intentions leading straight to hell.
- a good intent to help someone.

scenario exmaple:
- a chatbot designed for people with depressia to help them get through the day. the ai is learning based on the users writing.
- ai judging people for a loan, knowing that there might be bias if it's trained on the outcome of loans.

etchical dilemma:
- the ai learning 
- the developer knows that their ai is bias. but their boss wants them to ignore it. Their dilemma: do they risk their job or do they try to solve the bias.

when is it a good ethical dilemma:
1. when it is a realisitic case (this means we are able to remodel it)
2. can we recreate / simulate this scenario

acitivity:
human trained ai, vs adversarial network
A simple game with affordances. That can run on it's own or be played by humans.

1. user will go through a puzzle.
2. in the puzzle, the user is introduced to situation where there are ethical dilemma's.
3. this ethical dilemma is something that an ai developer could face.
4. the users is asked to make an desiscion.
5. all users train the ai that will compete with an adversarial network that has not been trained by humans.

1. we create an adversarial network.
2. we ask this ai to go through the same puzzle.

=
we are showing the comparisment of the ethically trained ai by humans vs the non trained ai.

is this trying to beat it? or is it trying to maximize "being good"?
- which people are going to work together? cooperative?
- which people are going to align to win?

- creating a textual questionloop with scenarios.
- creating a 3d space with some activities.
